\section{Wstęp}

\subsection{Motywacja}

  \begin{frame}{Motywacja}
    Szeroka klasa zagadnień -- szukanie najmniejszej wartości
    przyjmowanej przez funkcję jednej lub wielu zmiennych.

    \begin{exampleblock}{Przykłady}
      \begin{itemize}
        \item Produkcja - minimalizacja kosztów, przy zaspokojeniu popytu
        \item Zasoby ludzkie - problem przydziału godzin pracy
        \item Rolnictwo - dobór nawozów w celu maksymalizacji plonów
        \item Fizyka - wyznaczanie linii geodezyjnej w OTW
        \item \ldots
      \end{itemize}
    \end{exampleblock}
  \end{frame}

  \begin{frame}{Przykład klasyczny}
    \begin{exampleblock}{\textbf{Estymacja} parametrów modelu teoretycznego}
      \textbf{Minimalizacja} różnicy między danymi teoretycznymi,\\
        a eksperymentalnymi:
        \begin{gather*}
          min!F(x) = \sum_{i = 1}^{n} \left[ \frac{Y_i - T(x_i)}{\sigma_i}
          \right] ^2
        \end{gather*}
        $ n $ - liczba punktów doświadczalnych,
        $ K $ - liczba parametrów,\\
        $ \sigma_i $ - niepewność pomiaru $ x_i $,\\
        $ Y_i $ - zmierzona wartość w punkcie $ x_i $ \\
        $ T(x) $ - wartość teoretyczna dana funkcją o K parametrach,\\
        $ n \geq K{,}\ \text{zwykle}\ n \gg K $
    \end{exampleblock}
  \end{frame}

\subsection{Terminologia}

  \begin{frame}{Terminologia}
    \begin{block}{Terminologia}
      \begin{itemize}
        \item tradycyjnie: \textbf{minimalizacja}
        \item maksymalizacja $(F = -f(x))$
        \item optymalizacja -- kolizja z metodą teorii
        sterowania, (oparta o rachunek wariacyjny)
        \item b. stary termin: programowanie (liniowe,
        nieliniowe, matematyczne)
        \item ekstremalizacja
        \item mathematical optimization (function minimization)
      \end{itemize}
    \end{block}
  \end{frame}

\subsection{Zdefiniowanie zagadnienia}

  \begin{frame}{Zdefiniowanie zagadnienia}
    \begin{block}{Definicja}
      \textbf{Dane:} funkcja $F: A \rightarrow \mathbb{R}, A \subseteq \mathbb{R} $ \\
      \textbf{Szukane:} element $ x_{0} \in A \text{ taki, że } \forall x \in A \text{ } F(x_{0}) \le F(x) $
    \end{block}

    \begin{block}{Założenia}
      \begin{enumerate}
        \item Dla funkcji $ F $ może nie być znany wzór analityczny.
        \item Wartości $ x $ mogą być zawężone do pewnego
        ustalonego obszaru -- constrained minization.
        \item Mogą być dostępne $ \frac{\partial F}{\partial x} $.
        \item $ x_0 $ jest wyliczane procedurą -- wykorzystanie wielu wartości funkcji $ f(x) $,
        aż do osiągnięcia minimum.
      \end{enumerate}
    \end{block}
  \end{frame}

  \begin{frame}{Zdefiniowanie zagadnienia}
    \begin{block}{Kryteria wyboru najlepszej metody}
      Najlepsza metoda znajduje minimum (z zadaną tolerancją):
      \begin{itemize}
        \item po najmniejszej liczbie obliczeń wartości funkcji $ f $
        \item po najmniejszej liczbie kroków procedury -- niska złożoność obliczeniowa
        \item wymaga mało pamięci dodatkowej -- niska złożoność pamięciowa
      \end{itemize}
    \end{block}
  \end{frame}

\subsection{Gdzie szukać minimum globalnego funkcji?}

  \begin{frame}{Gdzie szukać minimum globalnego funkcji?}
    \begin{block}{$ F(x) $ przyjmuje minimum w jednym z punktów:}
      \begin{enumerate}
        \item p. stacjonarny -- wszystkie $ \frac{\partial F}{\partial x} = 0 $
        \item wierzchołek (cusp) -- niektóre $ \frac{\partial F}{\partial x} $ nie istnieją
        \item edge point -- na krawędzi obszaru
      \end{enumerate}
    \end{block}
    Gdy nie znamy funkcji analitycznie -- musimy ograniczyć
    się do minimum lokalnego $ x_0 $ -- \emph{unconstrained local minimization}.
    \begin{block}{Minimum lokalne}
      $\forall x \in U \text{, } F(x) \ge F(x_0)$, gdzie
      $ U $ - otoczenie punktu $ x_0 $
    \end{block}
  \end{frame}

\subsection{Kształt funkcji $ F(x) $}
  \begin{frame}{Kształt funkcji $ F(x) $ -- 1-D}
    \begin{block}{Założenie}
      $ F(x) $ -- ma sens fizyczny tj. w rozpatrywanym
      obszarze istnieją jej wszystkie pochodne.
    \end{block}
    Rozwijamy $F(x)$ wokół $x_0$ w \textbf{szereg Taylora (1-D)}:
    \begin{displaymath}
      F(x) = F(x_0) + \left. \frac{\partial F}{\partial x} \right|_{x_0}(x - x_0) +
      \left. \frac{1}{2} \frac{\partial^2 F}{\partial x^2} \right|_{x_0}(x - x_0)^2 +
      \dots
    \end{displaymath}
    \begin{itemize}
      \item Nie znamy obszaru jego zbieżności a priori.
      \item Im mniejsza wartość $ (x - x_0) $, tym mniej ważne człony
      wyższych rzędów.
    \end{itemize}
    \textbf{Konkluzja:} Dla małych kroków -- przewidywania oparte
    na wyrazach niższego rzędu powinny być wystarczające.

  \end{frame}

  \begin{frame}{Kształt funkcji $ F(x) $ -- n-D}
    Dla n-D: $ \vec{x} = x = [x_1, x_2, ..., x_n]^T $ \\
    \text{ } \\
    Rozwijamy funkcję $ F $ wokół $ \vec{x_0} $:
    \begin{displaymath}
      F(\vec{x}) = \underbrace{F(\vec{x_0})}_{\text{stały}} +
      \vec{g}^T * (\vec{x} - \vec{x_0}) +
      \frac{1}{2}(\vec{x} - \vec{x_0})^T * G * (\vec{x} - \vec{x_0}) + \dots
    \end{displaymath}
    \begin{displaymath}
      g_i = \left. \frac{\partial F}{\partial x} \right|_{\vec{x_0}} \text{-- gradient;}\quad
      G_{ij} = \left. \frac{\partial^2 F}{\partial x_i \partial x_j} \right|_{\vec{x_0}}
    \end{displaymath}

  \end{frame}

  \begin{frame}{Kształt funkcji $ F(x) $ -- n-D}
    \begin{enumerate}
      \item $ \vec{g}^T * (\vec{x} - \vec{x_0}) $ -- proporcjonalny do
      gradientu, wskazuje kierunek największego spadku funkcji.\\
      W pobliżu minimum: $ \vec{g} \to 0{, to}\ (\vec{x} - \vec{x_0}) \to 0
      \;$ -- człon liniowy, nie przepowiada minimum,
      nie można go użyć do określenia wielkości kroku.

      \item $ \frac{1}{2}((\vec{x} - \vec{x_0})^T) * G * (\vec{x} - \vec{x_0}) $
      -- kwadratowy, najniższy człon przydatny do przewidywania minimum.\\
      $ G \approx $ stałe na małych obszarach.
    \end{enumerate}

    \begin{alertblock}{Uwaga}
      Ta analiza nie jest słuszna dla $ F(\vec{x}) $ zależnych liniowo
      od $ \vec{x} $;\\
      \textbf{Wtedy:} Klasa problemów -- programowanie liniowe, rozwiązania leżą na krawędzi obszaru ograniczeń.
    \end{alertblock}
  \end{frame}

  \begin{frame}{Kształt funkcji $ F(x) $}
    \begin{block}{Optymalne algorytmy minimalizacji}
      Nie ma uniwersalnej metody minimalizacji. \\
      Dla bardzo złego algorytmu można znaleźć funkcję $ F(x) $,\\
      którą minimalizuje on najszybciej -- i~odwrotnie.
    \end{block}
    \begin{block}{Zasada doboru algorytmu optymalizacji}
      \textbf{Zasada:} Dla konkretnej funkcji należy indywidualnie dobrać algorytm minimalizacji.
    \end{block}

  \end{frame}
